<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Shuai Shao</title>
    <description>单纯明快</description>
    <link>http://shuai-shao.com//</link>
    <atom:link href="http://shuai-shao.com//feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Sun, 07 Feb 2021 23:17:41 -0800</pubDate>
    <lastBuildDate>Sun, 07 Feb 2021 23:17:41 -0800</lastBuildDate>
    <generator>Jekyll v3.0.2</generator>
    
      <item>
        <title>生动有趣的历史 - 读显微镜下的大明</title>
        <description>&lt;p&gt;最近读了一本颇为有趣的书，叫做显微镜下的大明。
本书主要讲述了四个明朝期间的诉讼案件：徽州丝绢案，婺源龙脉案，杨干禅院纠纷，和彭县小吏舞弊案。除了四个案件外，也花了很大的篇幅介绍了大明档案馆。通过几个案子，见微知著，一窥明朝的兴衰更替。历史不再囿于庙堂之上，不再只是帝王将相，而是更加生动活泼地浮现在眼前。
作者通过调研相关文档和史籍资料，梳理脉络，整理事件的来龙去脉，并以一种诙谐和有趣的方式给读者娓娓道来，乃为“知识的搬运工”的典范。
读此书时，除了觉得有趣，也有些零星的思考，记录在此：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;法律的精神：徽州丝绢案&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;古代徽州民风“健讼”。宋代欧阳修曾描述徽州民风：“民习律令，性喜讼。家家自为薄书，凡闻人之阴私毫发，坐起语言，日时皆记之，有讼则取以证”。也就是说，家家都有个小本本，时时记录街坊邻居的言行举止，打官司时便于取证。南宋时，徽州籍贯的理学大儒朱熹也无奈地评价老乡：“其俗难以力服，而易以理服”。
本书的四个案子中有三个发生在徽州附近，可见其“健讼”名不虚传。此外，本书成书主要依赖流传下来的档案和记录，可见徽州人在详尽记录和归档这件事情上做的很细致。
徽州人的这种民风，和现代欧美人很像，动辄兴讼，又做好了记录和证据，一切诉诸法理。这与最近看的另外一本书《乡土中国》中描述的中国乡土社会的长老权力 – 有了纠纷依赖调停和一些年高德劭的老人的裁决 – 是有所不同的。可以说，徽州人的这种习性，在古代中国，是个特例，而非常态。
而本章节依赖的档案资料《丝绢全书》，正是纠纷的一方一位叫程任卿的民意领袖在狱中所著。最难得的是，经过了几十年漫长的官司和争斗之后，程任卿虽然自认冤屈，却对《丝绢全书》没有任何裁剪修纂，而是始终保持客观中立，哪怕是对他不利或谩骂的文字，也一概收录，不改一字。如此详尽和不失偏颇的做法，令人赞叹。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;古代大数据：大明档案馆&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;大明档案馆，是修建于明朝初期位于南京玄武湖湖心岛上存放黄册的地方。从朱元璋洪武初年到明朝灭亡，每隔十年，全国各地都会修造黄册。黄册记录了各地具体到每家每户的人口，籍贯，性别，年龄，田地等等（与今日户口类似），这也是税赋的重要依据。黄册作为动态数据，每十年记录四项分项：旧管，新收，开除，实在，也就是相比较十年前的加减出入。为了校对和防止地方捏造数据，还引入和驳查机制。
从每家每户到县一级（如歙县）会有全县的统计数据，再汇总到府一级会有全府（如徽州府）的统计数据，再汇总到中央。各地造册时一式两份，一本蓝皮留在地方供查勘，一本黄皮上送中央留在玄武湖的档案馆作为权威备份。一旦地方关于人口土地有了纠纷，可申请查看黄册作为权威资料。
就这样，从洪武十四年到崇祯十五年，黄册一共修造了二十七期（明朝国祚270多年），累积黄册一百七十九万七千册，遍布在玄武湖诸岛上七百间的库册中。
想象一下：“在这座黄册库里，记录着整整一个王朝的田土盈缩，民生消长。你可以拉远视角，注视大明王朝跌宕起伏的一生；你也可以拉近视角，看到任何一个地区任何一个家庭的生老病死。起存储之巨，信息之丰，分列之细，是全世界档案史上从未有过的一个奇迹”。
插一句，这简直是一个爱好历史的数据科学家的梦想。假设这样一个黄册库在今天可以被数字化，大概一个硬盘便可以存下七百间库册约三百年的所有数据。而挖掘和分析这样的数据，能够有多少有意思的信息和故事能被发现，多少学术文章可以被发表，又有多少平民百姓走出枯燥的历史，成为一个个活生生的人？
“洪武初年在浙西耕作的农夫，永乐时迁至北京附近的军户，正统朝远在云南深山打猎的土司，正德朝在淮西烧盐的灶户，嘉靖朝山东进学的士子，万历朝建阳的书商子弟……几乎所有曾在这片土地生活过的大明子民，都在这座库房里有自己的一席之地。他们的身躯早已化为一抔黃土，名字却永远凝固在了这里。”
而这样一个详尽的档案库，最后的结局是什么呢？
崇祯十七年清兵南下攻打南京，明朝小朝廷手忙脚乱地备战。在这风雨飘摇的时候，玄武湖上的黄册库已经毫无用处。于是有人提议，把黄册的那些软纸一层层相叠锤实，剪裁成甲，作为防御的纸甲。另外，他们也被蘸上火药，用来作为药捻和引火折。
“这是一幕极具象征意味的画面。曾令大明江山永固的黄册，在风雨飘摇中被一一扯碎。漫天的纸屑飞舞于后湖之上，万亿大明子民的户籍化为甲胄和火器，以毁灭自己的方式，试图成为挽救这个王朝最后的希望。
这是大明保留下来的最后记忆。在这个王朝治下的每一个人–你能想象吗，几乎每一个人–后湖黄册库都记得，大明都记得。”
就这样，关于这些大明子民的记忆，随着他们的王朝，随风而去。&lt;/p&gt;

&lt;p&gt;[&lt;strong&gt;薛瑄&lt;/strong&gt;]&lt;/p&gt;

&lt;p&gt;在读最后一个小故事“正统年间的四条冤魂”时才初闻薛瑄，虽然笔墨不多，却立刻让我觉得这是一个了不起的人物。略作调研才发现自己才疏学浅，有眼不识泰山，这真的是一个值得好好说道的人。
(TBA)&lt;/p&gt;
</description>
        <pubDate>Sun, 07 Feb 2021 00:00:00 -0800</pubDate>
        <link>http://shuai-shao.com//2021/daming/</link>
        <guid isPermaLink="true">http://shuai-shao.com//2021/daming/</guid>
        
        <category>books</category>
        
        
        <category>books</category>
        
      </item>
    
      <item>
        <title>2021读书计划和书单</title>
        <description>&lt;p&gt;2021 目标: 读完25本书&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://book.douban.com/subject/1089243//&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;黄金时代&lt;/strong&gt;&lt;/a&gt;: 1/9-1/14, 6.5/10&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://book.douban.com/subject/30414743/&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;显微镜下的大明&lt;/strong&gt;&lt;/a&gt;: 1/10-1/20, 8/10&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://book.douban.com/subject/1795079/&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;乡土中国&lt;/strong&gt;&lt;/a&gt;: 1/21-1/27, 8/10&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://book.douban.com/subject/6313496/&quot; target=&quot;_blank&quot;&gt;卡拉马佐夫兄弟&lt;/a&gt;: 1/27-&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://book.douban.com/subject/34990839/&quot; target=&quot;_blank&quot;&gt;地下室笔记&lt;/a&gt;: 2/6-&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.goodreads.com/book/show/33369254-the-manager-s-path&quot; target=&quot;_blank&quot;&gt;The manager’s path&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.goodreads.com/book/show/34890015-factfulness&quot; target=&quot;_blank&quot;&gt;Factfulness&lt;/a&gt;: (Audio)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.goodreads.com/book/show/44525305-the-ride-of-a-lifetime&quot; target=&quot;_blank&quot;&gt; The ride of a lifetime&lt;/a&gt;: (Audio) 2/7-&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.goodreads.com/book/show/10884.Einstein&quot; target=&quot;_blank&quot;&gt;Einstein&lt;/a&gt;: (Audio)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.goodreads.com/book/show/324750.High_Output_Management&quot; target=&quot;_blank&quot;&gt;High output management&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;TBA&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 07 Feb 2021 00:00:00 -0800</pubDate>
        <link>http://shuai-shao.com//2021/book-list-2021/</link>
        <guid isPermaLink="true">http://shuai-shao.com//2021/book-list-2021/</guid>
        
        <category>books</category>
        
        
        <category>books</category>
        
      </item>
    
      <item>
        <title>An Overview of Interpretable Machine Learning</title>
        <description>&lt;p&gt;Definition of interpretability ([1], [2])
Though there is little consensus on a formal definition of  interpretability in machine learning, one good definition is that interpretability is the ability to explain or to present in understandable terms  to a human.&lt;/p&gt;

&lt;p&gt;Why interpretability?
Model interpretability is used to confirm below desiderata of ML systems:
Fairness: protected groups are not discriminated against
Privacy: the method protects sensitive information in the data
Reliability: whether algorithms is robust under parameter or input variation
Causality: the predicted change in output due to a perturbation will occur in real system
Trust: confidence from human users&lt;/p&gt;

&lt;p&gt;-Regulations like GDPR and CCPA require algorithms that make decisions based on user-level predictions, which “significantly affect” users to provide explanation (“right to explanation”).&lt;/p&gt;

&lt;p&gt;Scope of interpretation
Algorithm transparency: how does the algorithm create the model (focus on the knowledge of the algorithm, not the data or learned model)
Global model interpretability: comprehend the model at once, difficult to achieve due to the limitation of humans (imagine visualizing  a 5-dimensional hyperplane)
Interpret model prediction on a single instance&lt;/p&gt;

&lt;p&gt;Properties of good explanations
Contrastive:
Selective:
Social:
Focus on abnormal:
Truthful:
Consistent with prior beliefs:
General and portable:&lt;/p&gt;

&lt;p&gt;Evaluation Methods ([2]):
Application level evaluation: real humans, real tasks.
Human level evaluation: real humans, simplified tasks
Function level evaluation: no humans, proxy tasks&lt;/p&gt;

&lt;p&gt;Taxonomy of interpretation methods:
Feature summary statistics, feature summary visualization, model internals, data point, intrinsically interpretable model&lt;/p&gt;

&lt;p&gt;Interpretable Models
Linear models:
Easy to interpret when the number of features is limited (feature selection methods like LASSO can be used to restrict the number of features)
Interpretation:
Increasing the numerical feature by one unit changes the estimated outcome by its weight (numerical feature)
Changing the feature from the reference category to the other category changes the estimated outcome by the feature’s weight (categorical feature)
The importance of a feature in a linear regression model can be measured by the absolute value of its t-statistic
Visualization methods include weight plot, effect plot
For logistic regression, increasing the numerical feature by one unit changes the logarithm of the odds by its weight
Similar interpretations apply to other GLM or GAM models
Pros: universal, well-studied and accepted, backed up with statistical theories (confidence intervals, significant tests etc.)
Cons: assumptions on data generation process may not be valid, model performance sometimes often less than optimal, number of ways to transform model and features could be overwhelming&lt;/p&gt;

&lt;p&gt;Decision trees:
Simple interpretation: starting from the root node of the tree, traverse till the leaf node, obtain a path connecting conditions explaining why the prediction was made
The overall importance of a feature is the summed reduction of Gini index
Pros: capturing interactions between features, has a natural visualization, create human-friendly explanations, no need to transform features
Cons: fails to deal with linear relationships, which goes hand in hand with the lack of smoothness; unstable (a few changes in the training dataset can create a completely different tree); only interpretable when they are short (the number of terminal nodes increases quickly with depth)&lt;/p&gt;

&lt;p&gt;RuleFit ([7]):
Learns sparse linear models which include automatically detected interaction effects in the form of decision rules
First train an ensemble of trees (e.g random forest) based on the task of predicting the outcome of interest; Discard the prediction result but keep the decision rules decomposed from the trained trees, and train a sparse linear regression model (e.g LASSO)  using the original features and the additional features from the decision trees
Pros: automatically adds feature interaction to the linear models, good interpretable when rules are not too complicated (e.g maximum depth of the trees less than 3)
Cons: interpretability degrades with the increasing number of features, the performance of the model may not be optimal&lt;/p&gt;

&lt;p&gt;Model-agnostic Methods
Flexible, same method can be used for any type of underlying models.&lt;/p&gt;

&lt;p&gt;Partial Dependence Plot (PDP)
A global method: The method considers all instances and gives a statement about the global relationship of a feature with the predicted outcome.
Shows the marginal effect one or two features have on the predicted outcome of an ML model, estimated by calculating averages in the training data
Assumes no correlation between the feature of interest and the rest of the features
Pros: intuitive, clear interpretation, easy to implement, has a causal interpretation
Cons: maximum number of features in a PDP is two (due to human perception limitation), assumption of independence can be problematic, not revealing heterogeneous effects&lt;/p&gt;

&lt;p&gt;Individual Conditional Expectation (ICE)
One line per instance that shows how the prediction for the instance changes when a feature changes
PDP is the average of the lines in ICE; the two can be combined together
Pros: even more understandable than PDP, can uncover heterogeneous effects
Cons: same cons as PDP, plus can be overcrowded&lt;/p&gt;

&lt;p&gt;Accumulated Local Effects (ALE) ([9])
A fast and unbiased alternative to PDP, which describes how features influence the predictions of an ML model on average
Addresses the feature interaction problem with PDP and ICE
Calculates the differences in predictions instead of averages based on the conditional distribution of the features (instead of the marginal distribution in PDP and ICE)
ALE is preferred over PDP as a rule of thumb
Pros: unbiased (still works when features are correlated), faster to compute than PDPs, clear interpretation
Cons: can be a bit shaky based on the selection of intervals, not accompanied by ICE&lt;/p&gt;

&lt;p&gt;Feature Interaction ([7])
When features interact, the prediction cannot be expressed as the sum of the feature effect. One way to estimate the interaction strength is through Friedman’s H-statistic, which is the difference between the observed partial dependence function and the decomposed one without interactions. Friedman and Popescu also proposed a test statistic to evaluate whether the H-statistic differs significantly from zero.
Pros: backed up by underlying theory, possible to analyze higher order interactions, dimensionless and between 0 and 1
Cons: computationally expensive, the statistic is not yet available in a model-agnostic version&lt;/p&gt;

&lt;p&gt;Feature Importance
Permutation importance: increase in the prediction error after we permute the feature’s values
A feature is ‘important’ if shuffling its values increases the model error, because in this case the model relied on the feature for the prediction
When two features interact with each other, the importance of the interaction is included in the importance measurement of both features, the sum is larger than the drop in performance.
Not clear whether should compute importance on training or test data
Pros: easy interpretation, highly compressed, global insight, does not require retraining the model
Cons: unclear whether compute on training or test data, need access to the true outcome, depends on shuffling the feature which adds randomness, biased when features interact, adding a correlated feature can decrease the importance of the associated feature by splitting the importance between both features&lt;/p&gt;

&lt;p&gt;Global Surrogate
An interpretable model (linear model, decision tree etc.) trained to approximate the predictions of a black box model. The labels are the output of the black box model instead of the true labels.
Not too useful. There’s a trade-off between approximation accuracy and interpretability of the surrogate model.
Pros: flexible, intuitive, easy to measure performance by R-square
Cons: no clear cut for R-square, could close to the black box model on one dataset but diverge on another&lt;/p&gt;

&lt;p&gt;Local Surrogate (LIME) ([10])
Interpretable models that are used to explain individual predictions of black box ML models
Local interpretable model-agnostic explanations (LIME) generates a new dataset consisting of perturbed samples and the corresponding predictions of the black box model. On this new dataset LIME then trains an interpretable model, which is weighted by the proximity of the sampled instances to the instance of interest.
The learned model should be a good approximation of the machine learning model predictions locally, but it does not have to be a good global approximation.
Different methods are used to generate  the perturbed samples for different data formats: superpixels for images, randomly removing words for texts etc.
Pros: explanations are short and contrastive, works for tabular data, images, and texts, have a good fidelity measure
Cons: a correct definition of neighbors remains unresolved for tabular data, current sampling method ignores feature interaction, instability
Note: the method is promising but is still in development, where research opportunities lie&lt;/p&gt;

&lt;p&gt;Integrated Gradients ([4])
Integration of the gradients of predictions with respect to features, along the linear interpolation path between the instance of interest and a baseline instance.
Satisfies two desirable characteristics (axioms) for feature attribution methods: sensitivity and implementation invariance; also proved that previous methods DeepLift, Layer-wise relevance propagation (LRP), de-convolutional network, and guided-back-propagation violated one axiom or the other.
Fast and scalable, only requires a few calls to the gradient operator (compared to the Shapley Values)&lt;/p&gt;

&lt;p&gt;Shapley Values
A method from coalitional game theory, which describes how to fairly distribution the prediction among the features
The Shapley value is the average marginal distribution of a feature value across all possible coalitions, which is a computation of feature contributions for single predictions for any machine learning model
The only attribution method that satisfies efficiency, symmetry, dummy, and additivity, which together can be the definition of a fair payout
Shapley values might be the only method to deliver a full explanation. In situations where law requires explainability - like GDPR’s ‘right to explanations’,  the Shapley values might be the only legally compliant method, since it’s based on a solid theory, and distributes the effects fairly
Very expensive to compute, usually through Monte-Carlo sampling
Pros: the difference between the prediction and the average prediction is fairly distributed among the features of the instance, allows contrastive explanation, backed up by a solid theory
Cons: computationally expensive, sampling may increase variance, use all features thus not sparse, no prediction model like LIME (where you can make hypothetical statements), problematic when features are correlated as sampling from the feature’s marginal distribution
Note: open research problem as of how to sample when features are correlated&lt;/p&gt;

&lt;p&gt;SHAP&lt;/p&gt;

&lt;p&gt;Example-based Explanations&lt;/p&gt;

&lt;p&gt;Counterfactual Explanations
Adversarial Examples
Prototypes and Criticisms
Influential Instances&lt;/p&gt;

&lt;p&gt;Resources:
[1] Interpretable Machine Learning Book (link)
[2] Towards a rigorous science of interpretable machine learning (link)
[3] Explaining explainability (link)
[4] Interpretable Machine Learning: the fuss, the concrete and the questions (link)&lt;br /&gt;
[5] Axiomatic Attribution for deep networks (link)
[6]A unified approach to interpreting model predictions (link)
[7] Predictive learning via rule ensembles (link)
[8] Captum: a model interpretability and understanding library for PyTorch (link)
[9] Visualizing the Effects of Predictor Variables in Black Box Supervised Learning Models (link)
[10] Why should I trust you?: Explaining the predictions of any classifier (link)&lt;/p&gt;
</description>
        <pubDate>Wed, 15 Jan 2020 00:00:00 -0800</pubDate>
        <link>http://shuai-shao.com//2020/machine-learning-interpretability/</link>
        <guid isPermaLink="true">http://shuai-shao.com//2020/machine-learning-interpretability/</guid>
        
        <category>data</category>
        
        <category>machine learning</category>
        
        <category>statistics</category>
        
        <category>interpretable ml</category>
        
        
        <category>data</category>
        
      </item>
    
      <item>
        <title>Interesting Research Topics</title>
        <description>&lt;p&gt;1.Explainability of Deep Learning
2. Ranking problems&lt;/p&gt;
</description>
        <pubDate>Sun, 27 Oct 2019 00:00:00 -0700</pubDate>
        <link>http://shuai-shao.com//2019/research_topicsmd/</link>
        <guid isPermaLink="true">http://shuai-shao.com//2019/research_topicsmd/</guid>
        
        <category>data</category>
        
        <category>machine learning</category>
        
        <category>statistics</category>
        
        
        <category>data</category>
        
      </item>
    
      <item>
        <title>Singular-value Decomposition</title>
        <description>&lt;p&gt;Singular-value Decomposition is widely used in collaborative filtering.&lt;br /&gt;
Imagine you are building a recommendation system for recommending books to users. You have m users and n potential books to recommend. You also have some historical ratings of some users on some books.&lt;br /&gt;
Based on this, you can formulate a utility matrix where each row represents a user and each column represents a book. You can, of course, calculate the correlation between users or books and recommend based on a correlation weighted ratings average, but the problem with that is the matrix is very sparse (you have lots of empty entries), and the process is very computationally expensive (hard to scale).&lt;br /&gt;
An idea to resolve this is to factorize the utility matrix using singular-value decomposition. By using, you can decompose the m&lt;em&gt;n matrix into three matrices: A = USV^T - m&lt;/em&gt;n = (m&lt;em&gt;k) * (k&lt;/em&gt;k) * (k*n). The idea is to do dimension reduction by extracting  latent factors from the utility matrix (and hopefully still preserves most variance). Intuitively, this is similar to finding a low dimensional manifold out of a high dimensional space. By doing so, you are able to represent information in a condenser way, and thus mitigate the data sparsity and computationally issue.&lt;br /&gt;
Following up on the above book recommendation example. Intuitively what we are doing here is finding k most ‘important’ features and project users and books onto the k-dimensional space these k features define. For example, one feature could be the genre of the book, another could be the language of the book. Both U and V are singular matrices. Each row of U represents an eigenvector for a user. Each column of V^T represents an eigenvector for a book. S is a diagonal matrix and each diagonal entry represents an eigenvalue (strength of the latent factor). The predicted rating from user i to book j will simply be a summation of the projection of i on dimension k, projection of j on dimension k, and the strength of dimension k over all k dimensions.&lt;br /&gt;
(Get the picture right, and SVD is easy to understand)&lt;/p&gt;
</description>
        <pubDate>Mon, 25 Jun 2018 00:00:00 -0700</pubDate>
        <link>http://shuai-shao.com//2018/label_propagation/</link>
        <guid isPermaLink="true">http://shuai-shao.com//2018/label_propagation/</guid>
        
        <category>data</category>
        
        
        <category>data</category>
        
      </item>
    
      <item>
        <title>Label Propagation</title>
        <description>&lt;p&gt;Label propagation&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition&lt;/strong&gt;
Label propagation is a semi-supervised learning algorithm that assigns labels to previously unlabeled data points. It is a type of transductive learning.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Label Propagation on Graphs&lt;/strong&gt;
Only a subset of nodes in a graph is labeled. The task is to label  all nodes in a graph structure.  The underlying assumption is that linked nodes are correlated.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Math&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;
* Zoubin:
    * learning from labeled and unlabeled data with label propagation (paper) (http://mlg.eng.cam.ac.uk/zoubin/papers/CMU-CALD-02-107.pdf)
    * graph based semi-supervised learning (slides) (http://mlg.eng.cam.ac.uk/zoubin/talks/lect3ssl.pdf)
    * graph based semi-supervised learning (video) (https://www.youtube.com/watch?v=HZQOvm0fkLA)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Zhukov, label propagation on graphs: slides (http://www.leonidzhukov.net/hse/2015/networks/lectures/lecture17.pdf), video1, (https://www.youtube.com/watch?v=hmashUPJwSQ&amp;amp;t=804s) video2 (https://www.youtube.com/watch?v=F4f247IyOTs&amp;amp;t=2699s)&lt;/li&gt;
  &lt;li&gt;semi-supervised learning literature survey (http://pages.cs.wisc.edu/~jerryzhu/pub/ssl_survey.pdf)&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 15 Jun 2018 00:00:00 -0700</pubDate>
        <link>http://shuai-shao.com//2018/SVD/</link>
        <guid isPermaLink="true">http://shuai-shao.com//2018/SVD/</guid>
        
        <category>data</category>
        
        
        <category>data</category>
        
      </item>
    
      <item>
        <title>2018读书计划和书单</title>
        <description>&lt;p&gt;2018：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Longitude-Genius-Greatest-Scientific-Problem/dp/080271529X&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;The longitude&lt;/strong&gt;&lt;/a&gt;: 8/10&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Housekeeper-Professor-Yoko-Ogawa/dp/0312427808&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;The housekeeper and the professor&lt;/strong&gt;&lt;/a&gt;: 7/10&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Then-There-Were-None/dp/0062073486&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;And then there were none&lt;/strong&gt;&lt;/a&gt;: 8/10&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Bit-Social-Research-Digital-Age/dp/0691158649&quot; target=&quot;_blank&quot;&gt;Bit by bit&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Getting-Yes-Negotiating-Agreement-Without/dp/0140157352&quot; target=&quot;_blank&quot;&gt;Getting to yes&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Idea-Factory-Great-American-Innovation/dp/0143122797&quot; target=&quot;_blank&quot;&gt;The idea factory&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 15 Jun 2018 00:00:00 -0700</pubDate>
        <link>http://shuai-shao.com//2018/book-list-2018/</link>
        <guid isPermaLink="true">http://shuai-shao.com//2018/book-list-2018/</guid>
        
        <category>books</category>
        
        
        <category>books</category>
        
      </item>
    
      <item>
        <title>30%与100%</title>
        <description>&lt;p&gt;对我来说，30%是很容易放弃的时候。&lt;br /&gt;
6mile的trail，往往一迈多的时候就不想爬了。工作也是：  &lt;br /&gt;
前20%是蜜月期，借着新鲜感和鸡血往往每天早上还能很high地满血复活；进入四五个月以后，就疲态略显。 
然而我也是度过了30%就越爬越high的人，70%－100%阶段的快感是最大的。&lt;br /&gt;
再想想自己的初心，再坚持一下，再努力一点。&lt;/p&gt;
</description>
        <pubDate>Wed, 29 Mar 2017 00:00:00 -0700</pubDate>
        <link>http://shuai-shao.com//2017/work-30_percent/</link>
        <guid isPermaLink="true">http://shuai-shao.com//2017/work-30_percent/</guid>
        
        <category>misc</category>
        
        
        <category>misc</category>
        
      </item>
    
      <item>
        <title>追本溯源与单纯明快</title>
        <description>&lt;p&gt;做好一件事情就好了，所以要想的，是怎么突破自己的极限。&lt;br /&gt;
热情，动力，和掌控，都来源于对终极目标的明确；从此出发，去探索和延伸，从内而外，并以此目标判断日常是否值得去做，赋予日常以意义，才能做好，做的开心。&lt;br /&gt;
反之，则是被动和无穷的应付。&lt;br /&gt;
对于现在的工作，我该思考的唯一目标，就是：&lt;br /&gt;
怎么把model做到最好，并发挥最大的影响力？&lt;br /&gt;
从此出发，应该主动去探索model本身的可能性，学习，实验，测量，提高准确度；同时，怎样去推广，让别的组尽可能多的去用。&lt;br /&gt;
以此为尺，赋予日常以意义，才能真正的单纯明快。&lt;/p&gt;
</description>
        <pubDate>Thu, 26 Jan 2017 00:00:00 -0800</pubDate>
        <link>http://shuai-shao.com//2017/work/</link>
        <guid isPermaLink="true">http://shuai-shao.com//2017/work/</guid>
        
        <category>misc</category>
        
        
        <category>misc</category>
        
      </item>
    
      <item>
        <title>2017我的旅行计划</title>
        <description>&lt;p&gt;&lt;img src=&quot;/images/blogs/magnets2017.jpg&quot; alt=&quot;magnets&quot; /&gt;
英国&amp;amp;法国&lt;br /&gt;
加拿大&lt;br /&gt;
南美：阿根廷/玻利维亚/秘鲁&lt;/p&gt;

</description>
        <pubDate>Fri, 13 Jan 2017 00:00:00 -0800</pubDate>
        <link>http://shuai-shao.com//2017/my-travel-plan/</link>
        <guid isPermaLink="true">http://shuai-shao.com//2017/my-travel-plan/</guid>
        
        <category>travel</category>
        
        
        <category>travel</category>
        
      </item>
    
  </channel>
</rss>
